/gpu-benchmark/llm$ python llm_benchmark.py
/home/hhau/code/repos/gpu-benchmark/llm/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
--------------------------------------------------
🚀 Benchmarking Model: gpt2
--------------------------------------------------
Using device: CUDA (single GPU)
✅ Model loaded in: 1.22 seconds

--- Benchmark Results ---
📝 Prompt: 'Hello, my name is'
📜 Generated Output (50 tokens): ' John. I'm a writer, and I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm...'

--- Performance ---
⏱️ Total Generation Time: 0.88 s
⚡ Tokens per Second (TPS): 56.83 tokens/s

--- Hardware Utilization ---
🧠 Peak CPU Usage: 7.80%
💾 Peak System RAM Usage: 2763.54 MB
🎮 VRAM Used for Model: 767.53 MB
📈 Additional VRAM for Generation: 28.00 MB
🔝 Peak VRAM Usage: 795.53 MB
--------------------------------------------------

--------------------------------------------------
🚀 Benchmarking Model: distilgpt2
--------------------------------------------------
Using device: CUDA (single GPU)
✅ Model loaded in: 0.84 seconds

--- Benchmark Results ---
📝 Prompt: 'Hello, my name is'
📜 Generated Output (50 tokens): ' J.J.K. Rowling. I am a fan of the series and I am a fan of the series. I am a fan of the series and I am a fan of the series. I am a fan of the series and I am...'

--- Performance ---
⏱️ Total Generation Time: 0.29 s
⚡ Tokens per Second (TPS): 174.32 tokens/s

--- Hardware Utilization ---
🧠 Peak CPU Usage: 5.90%
💾 Peak System RAM Usage: 2783.87 MB
🎮 VRAM Used for Model: 795.53 MB
📈 Additional VRAM for Generation: 0.00 MB
🔝 Peak VRAM Usage: 795.53 MB
--------------------------------------------------