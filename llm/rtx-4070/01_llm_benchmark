/gpu-benchmark/llm$ python llm_benchmark.py
/home/hhau/code/repos/gpu-benchmark/llm/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
--------------------------------------------------
🚀 Benchmarking Model: gpt2
--------------------------------------------------
Using device: CUDA (single GPU)
✅ Model loaded in: 3.07 seconds

--- Benchmark Results ---
📝 Prompt: 'Hello, my name is'
📜 Generated Output (50 tokens): ' John. I'm a writer, and I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm...'

--- Performance ---
⏱️ Total Generation Time: 1.70 s
⚡ Tokens per Second (TPS): 29.47 tokens/s

--- Hardware Utilization ---
🧠 Peak CPU Usage: 15.10%
💾 Peak System RAM Usage: 1401.97 MB
🎮 VRAM Used for Model: 1586.66 MB
📈 Additional VRAM for Generation: 29.12 MB
🔝 Peak VRAM Usage: 1615.79 MB
--------------------------------------------------

--------------------------------------------------
🚀 Benchmarking Model: distilgpt2
--------------------------------------------------
Using device: CUDA (single GPU)
✅ Model loaded in: 1.49 seconds

--- Benchmark Results ---
📝 Prompt: 'Hello, my name is'
📜 Generated Output (50 tokens): ' J.J.K. Rowling. I am a fan of the series and I am a fan of the series. I am a fan of the series and I am a fan of the series. I am a fan of the series and I am...'

--- Performance ---
⏱️ Total Generation Time: 0.37 s
⚡ Tokens per Second (TPS): 136.59 tokens/s

--- Hardware Utilization ---
🧠 Peak CPU Usage: 12.50%
💾 Peak System RAM Usage: 1437.47 MB
🎮 VRAM Used for Model: 1609.41 MB
📈 Additional VRAM for Generation: -0.31 MB
🔝 Peak VRAM Usage: 1609.10 MB
--------------------------------------------------