/gpu-benchmark/nvlink/scripts$ python 03_benchmark_resnet18_cifar10.py
Preparing CIFAR-10 dataset...
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 170M/170M [00:08<00:00, 20.7MB/s]
Dataset ready.
Found 2 GPUs!

Starting training on 1 GPU (cuda:0)...
Epoch 1/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:12<00:00,  7.84batch/s, loss=1.0730]
Epoch 2/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:09<00:00, 10.72batch/s, loss=0.9452]
Epoch 3/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:09<00:00, 10.78batch/s, loss=0.8669]

Time for 1 GPU: 31.05 seconds

Wrapping model with nn.DataParallel for multi-GPU training.
Starting training on device: cuda:0
Epoch 1/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:07<00:00, 13.07batch/s, loss=1.1344]
Epoch 2/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:06<00:00, 15.61batch/s, loss=0.9793]
Epoch 3/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:06<00:00, 15.33batch/s, loss=0.8314]

Time for 2 GPUs: 20.19 seconds

--- Benchmark Summary ---
Single GPU Time: 31.05 seconds
Multi-GPU Time:  20.19 seconds
Speedup: 1.54x